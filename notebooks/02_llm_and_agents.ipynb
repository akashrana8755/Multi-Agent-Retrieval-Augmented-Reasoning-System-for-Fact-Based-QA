{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67da0103",
   "metadata": {},
   "source": [
    "# ðŸ¤– Step 3: Load Mistral 7B on Apple Silicon and Define Reasoning Agents\n",
    "\n",
    "This notebook does:\n",
    "- Load Mistral 7B on Mac (CPU or Apple GPU)\n",
    "- Define four agents:\n",
    "  - Query Rewriter\n",
    "  - Document Retriever\n",
    "  - Fact Checker\n",
    "  - Synthesizer\n",
    "- Run a full agent chain manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "249199fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (4.53.2)\n",
      "Requirement already satisfied: accelerate in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (1.9.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (5.0.0)\n",
      "Requirement already satisfied: filelock in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: psutil in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall bitsandbytes -y\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install transformers accelerate sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "133148ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:935: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.33s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# Make sure you're logged in\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"  # will use MPS or CPU on Mac\n",
    ")\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    return_full_text=False,\n",
    "    temperature=0.7,\n",
    "    repetition_penalty=1.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eddea9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_mistral(prompt, system_prompt=None):\n",
    "    if system_prompt:\n",
    "        full_prompt = f\"<s>[INST] {system_prompt} [/INST] {prompt.strip()}</s>\"\n",
    "    else:\n",
    "        full_prompt = f\"<s>[INST] {prompt.strip()} [/INST]\"\n",
    "        \n",
    "    output = llm(full_prompt)[0][\"generated_text\"]\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "899d54ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital city of France is Paris.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_mistral(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67276595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rewriter_agent(user_question):\n",
    "    prompt = (\n",
    "        \"Rewrite the user's question to make it clearer for a document retrieval system. \"\n",
    "        \"Focus on making it specific and search-friendly.\\n\\n\"\n",
    "        f\"User question: {user_question}\"\n",
    "    )\n",
    "    return chat_with_mistral(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f16a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5e079db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parsed 3703344 documents\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load raw JSON\n",
    "with open(\"../data/raw/hotpot_train_v1.1.json\", \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# Flatten into list of {title, text}\n",
    "flattened_docs = []\n",
    "for entry in raw_data:\n",
    "    for title, paragraphs in entry[\"context\"]:\n",
    "        for para in paragraphs:\n",
    "            flattened_docs.append({\"title\": title, \"text\": para})\n",
    "\n",
    "print(f\"âœ… Parsed {len(flattened_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c9de8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (2/2 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3703344/3703344 [00:04<00:00, 742515.18 examples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved to ../data/hotpot_docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to HF Dataset\n",
    "dataset = Dataset.from_list(flattened_docs)\n",
    "\n",
    "# Create save folder\n",
    "os.makedirs(\"../data/hotpot_docs\", exist_ok=True)\n",
    "\n",
    "# Save to disk\n",
    "dataset.save_to_disk(\"../data/hotpot_docs\")\n",
    "print(\"âœ… Saved to ../data/hotpot_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c17b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_from_disk\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index(\"../data/vector_index/faiss_hotpot_ip.index\")\n",
    "\n",
    "# Load the document ID mapping (list of indices)\n",
    "with open(\"../data/vector_index/doc_lookup.pkl\", \"rb\") as f:\n",
    "    id_store = pickle.load(f)\n",
    "\n",
    "# Load the full document text dataset\n",
    "documents = load_from_disk(\"../data/hotpot_docs\")\n",
    "\n",
    "# Load the embedding model (same one used in Step 2)\n",
    "model_emb = SentenceTransformer(\"BAAI/bge-large-en\")\n",
    "\n",
    "# Define the retrieval agent\n",
    "def retrieval_agent(query, k=5):\n",
    "    # Convert question into embedding vector\n",
    "    q_vec = model_emb.encode(query, normalize_embeddings=True).astype(\"float32\")\n",
    "    \n",
    "    # Search the top-k most similar docs\n",
    "    D, I = index.search(q_vec.reshape(1, -1), k)\n",
    "    \n",
    "    # Return the top-k documents\n",
    "    return [documents[int(idx)][\"text\"] for idx in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "139442c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_checker_agent(original_question, retrieved_docs):\n",
    "    joined = \"\\n\\n\".join(retrieved_docs)\n",
    "    prompt = (\n",
    "        f\"Given the question:\\n{original_question}\\n\\n\"\n",
    "        f\"And the evidence:\\n{joined}\\n\\n\"\n",
    "        \"Decide whether the evidence supports the answer to the question. \"\n",
    "        \"If yes, summarize the proof. If not, say it's insufficient.\"\n",
    "    )\n",
    "    return chat_with_mistral(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a159eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_agent(question, retrieved_docs):\n",
    "    joined = \"\\n\\n\".join(retrieved_docs)\n",
    "    prompt = (\n",
    "        f\"Answer the following question using the information below.\\n\\n\"\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"Evidence:\\n{joined}\\n\\n\"\n",
    "        \"Give a well-reasoned answer with traceable justification.\"\n",
    "    )\n",
    "    return chat_with_mistral(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa0ea579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Rewriting...\n",
      "Can you provide me with the exact date when Sir Isaac Newton published his work \"Principia Mathematica\"?\n",
      "\n",
      "ðŸ“š Retrieving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 documents retrieved\n",
      "\n",
      "âœ… Fact Checking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evidence provided does not support the answer to the question. There are two ISBNs provided, which correspond to different editions of \"Principia\" with different publication dates. One edition was published in 1727, and the other in 1740. However, the question asks specifically about the publication date of the original edition, which is not mentioned anywhere in the evidence. Therefore, it is insufficient to determine the publication date of the original edition based on the information provided.\n",
      "\n",
      "ðŸ§  Synthesizing Answer...\n",
      "Isaac Newton published his work \"Principia Mathematica\" in three volumes in 1687. The evidence provided includes the ISBN numbers for these publications: ISBN 9781437788118 (for the first volume), ISBN 9781437788126 (for the second volume), and ISBN 9781437788133 (for the third volume).\n"
     ]
    }
   ],
   "source": [
    "user_question = \"When did Isaac Newton publish Principia?\"\n",
    "\n",
    "# Step 1: Query Rewrite\n",
    "print(\"ðŸ” Rewriting...\")\n",
    "rewritten = query_rewriter_agent(user_question)\n",
    "print(rewritten)\n",
    "\n",
    "# Step 2: Retrieve Docs\n",
    "print(\"\\nðŸ“š Retrieving...\")\n",
    "docs = retrieval_agent(rewritten)\n",
    "print(f\"{len(docs)} documents retrieved\")\n",
    "\n",
    "# Step 3: Fact Check\n",
    "print(\"\\nâœ… Fact Checking...\")\n",
    "fact_check = fact_checker_agent(user_question, docs)\n",
    "print(fact_check)\n",
    "\n",
    "# Step 4: Synthesis\n",
    "print(\"\\nðŸ§  Synthesizing Answer...\")\n",
    "final = synthesis_agent(user_question, docs)\n",
    "print(final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
