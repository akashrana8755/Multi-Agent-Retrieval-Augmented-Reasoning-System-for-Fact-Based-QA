{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67da0103",
   "metadata": {},
   "source": [
    "# 🤖 Step 3: Load Mistral 7B on Apple Silicon and Define Reasoning Agents\n",
    "\n",
    "This notebook does:\n",
    "- Load Mistral 7B on Mac (CPU or Apple GPU)\n",
    "- Define four agents:\n",
    "  - Query Rewriter\n",
    "  - Document Retriever\n",
    "  - Fact Checker\n",
    "  - Synthesizer\n",
    "- Run a full agent chain manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249199fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: transformers in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (4.53.2)\n",
      "Requirement already satisfied: accelerate in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (1.9.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (5.0.0)\n",
      "Requirement already satisfied: filelock in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: psutil in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall bitsandbytes -y\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install transformers accelerate sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "133148ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/akashrana/Downloads/Multi-Agent-Retrieval-Augmented-Reasoning-System-for-Fact-Based-QA/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:935: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.39s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# Make sure you're logged in\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"  # will use MPS or CPU on Mac\n",
    ")\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    return_full_text=False,\n",
    "    temperature=0.7,\n",
    "    repetition_penalty=1.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eddea9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_mistral(prompt, system_prompt=None):\n",
    "    if system_prompt:\n",
    "        full_prompt = f\"<s>[INST] {system_prompt} [/INST] {prompt.strip()}</s>\"\n",
    "    else:\n",
    "        full_prompt = f\"<s>[INST] {prompt.strip()} [/INST]\"\n",
    "        \n",
    "    output = llm(full_prompt)[0][\"generated_text\"]\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899d54ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital city of France is Paris.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_mistral(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67276595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rewriter_agent(user_question):\n",
    "    prompt = (\n",
    "        \"Rewrite the user's question to make it clearer for a document retrieval system. \"\n",
    "        \"Focus on making it specific and search-friendly.\\n\\n\"\n",
    "        f\"User question: {user_question}\"\n",
    "    )\n",
    "    return chat_with_mistral(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f16a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5e079db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parsed 3703344 documents\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load raw JSON\n",
    "with open(\"../data/raw/hotpot_train_v1.1.json\", \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# Flatten into list of {title, text}\n",
    "flattened_docs = []\n",
    "for entry in raw_data:\n",
    "    for title, paragraphs in entry[\"context\"]:\n",
    "        for para in paragraphs:\n",
    "            flattened_docs.append({\"title\": title, \"text\": para})\n",
    "\n",
    "print(f\"✅ Parsed {len(flattened_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c9de8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (2/2 shards): 100%|██████████| 3703344/3703344 [00:01<00:00, 3087128.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to ../data/hotpot_docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to HF Dataset\n",
    "dataset = Dataset.from_list(flattened_docs)\n",
    "\n",
    "# Create save folder\n",
    "os.makedirs(\"../data/hotpot_docs\", exist_ok=True)\n",
    "\n",
    "# Save to disk\n",
    "dataset.save_to_disk(\"../data/hotpot_docs\")\n",
    "print(\"✅ Saved to ../data/hotpot_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c17b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_from_disk\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index(\"../data/vector_index/faiss_hotpot_ip.index\")\n",
    "\n",
    "# Load the document ID mapping (list of indices)\n",
    "with open(\"../data/vector_index/doc_lookup.pkl\", \"rb\") as f:\n",
    "    id_store = pickle.load(f)\n",
    "\n",
    "# Load the full document text dataset\n",
    "documents = load_from_disk(\"../data/hotpot_docs\")\n",
    "\n",
    "# Load the embedding model (same one used in Step 2)\n",
    "model_emb = SentenceTransformer(\"BAAI/bge-large-en\")\n",
    "\n",
    "# Define the retrieval agent\n",
    "def retrieval_agent(query, k=5):\n",
    "    # Convert question into embedding vector\n",
    "    q_vec = model_emb.encode(query, normalize_embeddings=True).astype(\"float32\")\n",
    "    \n",
    "    # Search the top-k most similar docs\n",
    "    D, I = index.search(q_vec.reshape(1, -1), k)\n",
    "    \n",
    "    # Return the top-k documents\n",
    "    return [documents[int(idx)][\"text\"] for idx in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139442c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_checker_agent(original_question, retrieved_docs):\n",
    "    joined = \"\\n\\n\".join(retrieved_docs)\n",
    "    prompt = (\n",
    "        f\"Given the question:\\n{original_question}\\n\\n\"\n",
    "        f\"And the evidence:\\n{joined}\\n\\n\"\n",
    "        \"Decide whether the evidence supports the answer to the question. \"\n",
    "        \"If yes, summarize the proof. If not, say it's insufficient.\"\n",
    "    )\n",
    "    return chat_with_mistral(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a159eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesis_agent(question, retrieved_docs):\n",
    "    joined = \"\\n\\n\".join(retrieved_docs)\n",
    "    prompt = (\n",
    "        f\"Answer the following question using the information below.\\n\\n\"\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"Evidence:\\n{joined}\\n\\n\"\n",
    "        \"Give a well-reasoned answer with traceable justification.\"\n",
    "    )\n",
    "    return chat_with_mistral(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa0ea579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Rewriting...\n",
      "Could you please provide me with the precise date when Sir Isaac Newton published his work \"Principia Mathematica\"?\n",
      "\n",
      "📚 Retrieving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 documents retrieved\n",
      "\n",
      "✅ Fact Checking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given evidence does not support the question about when Isaac Newton published Principia as it only provides information about other individuals such as Hermann Minkowski and Edmund Halley. Therefore, this evidence is insufficient to provide an accurate answer to the question.\n",
      "\n",
      "🧠 Synthesizing Answer...\n",
      "The question asks when Isaac Newton published Principia. Unfortunately, there is no specific information provided in the evidence that can help us accurately determine the year of publication. The first edition of Principia Mathematica, which was edited by John Collins and published by George Bentley, was released on March 31, 1727. However, it is possible that this is not the edition or version that the original question refers to. Without more context or specific information about the edition or version in question, we cannot provide a definitive answer.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"When did Isaac Newton publish Principia?\"\n",
    "\n",
    "# Step 1: Query Rewrite\n",
    "print(\"🔁 Rewriting...\")\n",
    "rewritten = query_rewriter_agent(user_question)\n",
    "print(rewritten)\n",
    "\n",
    "# Step 2: Retrieve Docs\n",
    "print(\"\\n📚 Retrieving...\")\n",
    "docs = retrieval_agent(rewritten)\n",
    "print(f\"{len(docs)} documents retrieved\")\n",
    "\n",
    "# Step 3: Fact Check\n",
    "print(\"\\n✅ Fact Checking...\")\n",
    "fact_check = fact_checker_agent(user_question, docs)\n",
    "print(fact_check)\n",
    "\n",
    "# Step 4: Synthesis\n",
    "print(\"\\n🧠 Synthesizing Answer...\")\n",
    "final = synthesis_agent(user_question, docs)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44c58c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_question: str\n",
    "    rewritten_question: str\n",
    "    retrieved_docs: List[str]\n",
    "    fact_check: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3967bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_node(state: AgentState) -> AgentState:\n",
    "    rewritten = query_rewriter_agent(state[\"user_question\"])\n",
    "    return {**state, \"rewritten_question\": rewritten}\n",
    "\n",
    "def retrieve_node(state: AgentState) -> AgentState:\n",
    "    docs = retrieval_agent(state[\"rewritten_question\"])\n",
    "    return {**state, \"retrieved_docs\": docs}\n",
    "\n",
    "def factcheck_node(state: AgentState) -> AgentState:\n",
    "    check = fact_checker_agent(state[\"user_question\"], state[\"retrieved_docs\"])\n",
    "    return {**state, \"fact_check\": check}\n",
    "\n",
    "def synthesize_node(state: AgentState) -> AgentState:\n",
    "    final = synthesis_agent(state[\"user_question\"], state[\"retrieved_docs\"])\n",
    "    return {**state, \"answer\": final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88734fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"rewrite\", rewrite_node)\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"factcheck\", factcheck_node)\n",
    "graph.add_node(\"synthesize\", synthesize_node)\n",
    "\n",
    "graph.set_entry_point(\"rewrite\")\n",
    "graph.add_edge(\"rewrite\", \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"factcheck\")\n",
    "graph.add_edge(\"factcheck\", \"synthesize\")\n",
    "graph.add_edge(\"synthesize\", END)\n",
    "\n",
    "rag_graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c8825b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Rewritten Query:\n",
      " Could you please provide me with the specific date when Sir Isaac Newton published his magnum opus, \"Mathematical Principles of Natural Philosophy,\" commonly known as the \"Principia\"?\n",
      "\n",
      "📚 Top Retrieved Doc:\n",
      " Aristotle ( ; Greek: Ἀριστοτέλης , , \"Aristotélēs\"; 384–322 BC) was an ancient Greek philosopher and scientist born in the city of Stagira, Chalkidice, on the northern periphery of Classical Greece.\n",
      "\n",
      "✅ Fact Check:\n",
      " The evidence provided does not support the answer to the question. It includes information about various notable scientists and the founding of a scientific journal, but none of it directly relates to when Isaac Newton published the Principia.\n",
      "\n",
      "🧠 Final Answer:\n",
      " It is not clear from the provided evidence when Isaac Newton published the Principia.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"When did Isaac Newton publish the Principia?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"user_question\": user_input\n",
    "}\n",
    "\n",
    "final_state = rag_graph.invoke(initial_state)\n",
    "\n",
    "print(\"🔁 Rewritten Query:\\n\", final_state[\"rewritten_question\"])\n",
    "print(\"\\n📚 Top Retrieved Doc:\\n\", final_state[\"retrieved_docs\"][0][:500])\n",
    "print(\"\\n✅ Fact Check:\\n\", final_state[\"fact_check\"])\n",
    "print(\"\\n🧠 Final Answer:\\n\", final_state[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
